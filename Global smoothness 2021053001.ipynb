code for balanced policy evaluation, under global smoothness assumptions. 

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42013332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 5952\n",
      "Academic license - for non-commercial use only - expires 2021-07-27\n",
      "Using license file C:\\Users\\yunfa\\gurobi.lic\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-10d8d97ae8aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;31m#m.params.method=0#0 is primal simplex, 1 is dual simplex, 2 is barrier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'optimization time: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gurobipy import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import statistics\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#command to open console for testing \n",
    "#%qtconsole\n",
    "\n",
    "t = time.time()\n",
    "#parameters\n",
    "sigma=2\n",
    "lamda=1\n",
    "\n",
    "#load dataset\n",
    "df = pd.read_csv('NomisB_e-Car_Data_3.csv')\n",
    "sample_size = df.shape[0]\n",
    "X_data= np.array(df[['FICO','Amount','Cost of Funds',\n",
    "                      'term72','term66','term60','term48',\n",
    "                      'tier1','tier2','tier3',\n",
    "                      'quarter1','quarter2','quarter3',\n",
    "                      'year1','year2',\n",
    "                      'partnerbin1','partnerbin2',]])\n",
    "D_data = np.array(df[['Outcome']]).flatten()\n",
    "P_data = np.array(df[['Rate']]).flatten()\n",
    "dim=X_data.shape[1]\n",
    "\n",
    "#normalize all features and prices\n",
    "X_data = X_data / X_data.max(axis=0)\n",
    "\n",
    "#split dataset\n",
    "rndseed=252\n",
    "P_train, P_test, X_train,X_test, D_train,D_test =train_test_split(\n",
    "    P_data,X_data,D_data, test_size=0.95,random_state=rndseed)\n",
    "train_size=X_train.shape[0]\n",
    "test_size=X_test.shape[0]\n",
    "print('data size:',train_size)\n",
    "\n",
    "def new_policy(X,P):\n",
    "    return P\n",
    "\n",
    "Z_train=np.zeros((train_size,dim+1))\n",
    "for i in range(0,train_size):\n",
    "    Z_train[i]=np.append(X_train[i],5*P_train[i])#historical policy\n",
    "Y_train=np.zeros((train_size,dim+1))\n",
    "for i in range(0,train_size):\n",
    "    Y_train[i]=np.append(X_train[i],5*new_policy(X_train[i],P_train[i]))#new policy\n",
    "    \n",
    "#compute terms in objective, objective = w@A@w-w@b\n",
    "kernel = RBF(sigma)\n",
    "A=kernel(Z_train,Z_train)+np.identity(train_size)\n",
    "B=kernel(Z_train,Y_train)\n",
    "b=2*B@(np.ones(train_size)/train_size)\n",
    "\n",
    "#gram matrix\n",
    "# Z_and_Y=np.zeros((train_size*2,dim+1))\n",
    "# Z_and_Y[0:train_size,:]=Z_train\n",
    "# Z_and_Y[train_size:2*train_size,:]=Y_train\n",
    "# G=kernel(Z_and_Y)\n",
    "# for i in range(0,train_size):\n",
    "#     G[i][i]=G[i][i]+lamda#add variance term\n",
    "    \n",
    "# A=G[0:train_size,0:train_size]\n",
    "# B=G[0:train_size,train_size:2*train_size]\n",
    "\n",
    "#build optimization model\n",
    "m = Model()\n",
    "m.Params.LogToConsole = 0#suppress Gurobipy printing\n",
    "# Add variables\n",
    "w=m.addMVar ( train_size, ub=1.0,lb=-1.0,name=\"w\" )\n",
    "# Set objective function\n",
    "m.Params.OptimalityTol=0.01\n",
    "m.setObjective(w@A@w-w@b, GRB.MINIMIZE) \n",
    "# Add constraints\n",
    "m.addConstr(w@np.ones(train_size)==1)\n",
    "#m.params.method=0#0 is primal simplex, 1 is dual simplex, 2 is barrier\n",
    "m.update()\n",
    "m.optimize()\n",
    "\n",
    "print('optimization time: ',time.time() - t)\n",
    "#print key info for testing purpose\n",
    "obj = m.getObjective()\n",
    "print('optimal objective value: ',obj.getValue())\n",
    "w_star=np.zeros(train_size)\n",
    "for i in range(0,train_size):\n",
    "    w_star[i]=w[i].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87743a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal weights\n",
    "w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad959ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimated value of policy \n",
    "w_star@(np.multiply(D_train,P_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std of weights\n",
    "import statistics\n",
    "statistics.stdev(w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc9f11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.371959005376344"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#real value of original policy\n",
    "np.average(np.multiply(D_train,P_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
