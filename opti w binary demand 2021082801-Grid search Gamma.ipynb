{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885861f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import statistics\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "\n",
    "t_1 = time.time()\n",
    "#parameters\n",
    "X_multiplier=7#multiplier of X in demand calculation\n",
    "priceMultiplier=1#multiplier of price in kernel\n",
    "Gamma=3\n",
    "P_low=Gamma\n",
    "P_high=Gamma+7\n",
    "\n",
    "sigma=1#bandwidth of kernel\n",
    "dim=1#dim of feature X\n",
    "\n",
    "def policy_to_evaluate(x,p):\n",
    "    return 1.1*p\n",
    "\n",
    "def expected_demand(x_arr,p_arr):\n",
    "    #return (-p_arr+P_high)/(P_high-P_low)\n",
    "    p_arr=np.minimum(P_high,p_arr)\n",
    "    p_arr=np.maximum(P_low,p_arr)\n",
    "    return (x_arr*X_multiplier-p_arr+P_high)/(P_high-P_low+X_multiplier)\n",
    "\n",
    "def realized_demand(x_arr,p_arr,rndseed):\n",
    "    np.random.seed(rndseed+52028)\n",
    "    return np.random.binomial(1,expected_demand(x_arr,p_arr))\n",
    "    \n",
    "#generate training dataset\n",
    "rndseed=2352#927#2352\n",
    "train_size=30#100\n",
    "np.random.seed(rndseed+883)\n",
    "X_train=np.random.uniform(0,1,train_size)\n",
    "#np.random.seed(rndseed+5325)\n",
    "#P_train=np.random.uniform(P_low,P_high,train_size)\n",
    "P_train=P_high-(P_high-P_low)*X_train#deterministic pricing\n",
    "D_train=realized_demand(X_train,P_train,rndseed+917)\n",
    "\n",
    "#generate testing dataset\n",
    "P_test=np.zeros(train_size)\n",
    "for i in range(0,train_size):\n",
    "    P_test[i]=policy_to_evaluate(X_train[i],P_train[i])\n",
    "\n",
    "#pre-compute values needed\n",
    "R_train=np.multiply(D_train,P_train)\n",
    "expected_R_train=np.multiply(P_train,expected_demand(X_train,P_train))\n",
    "expected_R_test=np.multiply(P_test,expected_demand(X_train,P_test))\n",
    "expected_val_test=sum(expected_R_test)/train_size\n",
    "\n",
    "#for computing kernel only: normalize prices, and multiply by given factor\n",
    "P_train_norm=priceMultiplier*(P_train-P_low)/ (P_high-P_low)\n",
    "\n",
    "Z_train=np.zeros((train_size,dim+1))\n",
    "for i in range(0,train_size):\n",
    "    Z_train[i]=np.append(X_train[i],P_train_norm[i])#historical policy\n",
    "Y_train=np.zeros((train_size,dim+1))\n",
    "for i in range(0,train_size):\n",
    "    Y_train[i]=np.append(X_train[i],policy_to_evaluate(X_train[i],P_train_norm[i]))#new policy\n",
    "\n",
    "#gram matrix\n",
    "kernel = RBF(sigma)\n",
    "Z_and_Y=np.zeros((train_size*2,dim+1))\n",
    "Z_and_Y[0:train_size,:]=Z_train\n",
    "Z_and_Y[train_size:2*train_size,:]=Y_train\n",
    "G=kernel(Z_and_Y)\n",
    "G=G+0.0001*np.identity(train_size*2)#make G positive semi-definite\n",
    "C=np.linalg.cholesky(G*2)#C is lower triangular, CC^\\top=G\n",
    "\n",
    "#preparation\n",
    "rowSumHalfG=np.transpose(np.sum(G[:,train_size:2*train_size],axis=1).reshape(-1,1))#sum each row of right half of G\n",
    "D3=np.transpose(rowSumHalfG).dot(rowSumHalfG)/(train_size**2)#the third term in Dw\n",
    "arr_m=np.zeros((train_size,train_size*2,train_size*2))\n",
    "for i in range(0,train_size):\n",
    "    temp2=G[:,i].reshape(-1,1)\n",
    "    arr_m[i]=temp2.dot(np.transpose(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856408b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose penalty paramter for Nathan's method\n",
    "#input training features and realized revenue. output choice of parameter lambda\n",
    "def nathal_choose_param(Z_train,R_train): \n",
    "    #gram matrix\n",
    "    kernel = RBF(sigma)\n",
    "    K=kernel(Z_train)#computing kernel takes <1 sec\n",
    "    R_normalize=R_train-np.average(R_train)\n",
    "    #evals,evecs=np.linalg.eig(K)#this method is slow\n",
    "    evals=scipy.linalg.eigh(K, eigvals_only=True)#this method assumes real symmetric matrix, and is fast\n",
    "\n",
    "    #compute for each lamda\n",
    "    lamda_list=np.arange(1,51)/2#when using lambda<1, determinant of A will be zero, causing exp(det(A)) to return error\n",
    "    neg_log_likelihood_list=np.zeros(len(lamda_list))\n",
    "\n",
    "    for i in range(0,len(lamda_list)):\n",
    "        lamda=lamda_list[i]\n",
    "        A=K+lamda*np.identity(train_size)\n",
    "        b=np.linalg.solve(A, R_normalize)#solve the linear system instead of inverting A, takes 3-4 secs\n",
    "        #A_det=np.prod(lamda+evals)\n",
    "        log_det_A=sum(np.log(lamda+evals))\n",
    "        neg_log_likelihood_list[i]=np.transpose(R_normalize)@b+0.5*log_det_A\n",
    "        #no need to include the last term in log-likelihood, which is constant (0.5*train_size*math.log(2*math.pi))\n",
    "\n",
    "    optimal_lamda=lamda_list[np.argmin(neg_log_likelihood_list)]\n",
    "    \n",
    "    return optimal_lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a450d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nathan's method\n",
    "#input penalty parameter lambda. Output weights\n",
    "def nathans_method(lamda): \n",
    "    G_aug=np.copy(G)\n",
    "    for i in range(0,train_size):\n",
    "        G_aug[i][i]=G_aug[i][i]+lamda**2#add variance term\n",
    "\n",
    "    #evals and evectors of G\n",
    "    evals,evecs=scipy.linalg.eigh(G_aug, eigvals_only=False)#this method assumes real symmetric matrix, and is fast\n",
    "    A=np.diag(evals)\n",
    "    c=np.sum(evecs[0:train_size,0:2*train_size],axis=0)\n",
    "\n",
    "    #build optimization model\n",
    "    m = Model()\n",
    "    m.Params.LogToConsole = 0#suppress Gurobipy printing\n",
    "    # Add variables\n",
    "    v=m.addMVar ( train_size*2, ub=1.0,lb=-1.0,name=\"v\" )\n",
    "    # Set objective function\n",
    "    #m.Params.OptimalityTol=0.01\n",
    "    m.setObjective(v@A@v, GRB.MINIMIZE) \n",
    "    # Add constraints\n",
    "    m.addConstr(v@c==1)\n",
    "    m.addConstr(evecs[train_size:2*train_size,0:2*train_size]@v==-np.ones(train_size)/train_size)\n",
    "    #m.addConstr(S[0:train_size,0:2*train_size]@v>=-np.zeros(train_size))#w_i>=0\n",
    "    #m.params.method=0#0 is primal simplex, 1 is dual simplex, 2 is barrier\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "\n",
    "    #get weights\n",
    "    v_star=np.zeros(2*train_size)\n",
    "    for i in range(0,2*train_size):\n",
    "        v_star[i]=v[i].x\n",
    "    w=evecs[0:train_size,0:2*train_size]@v_star\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subroutine that computes phi(w) using Ben-tal's method\n",
    "#input: starting weights. output: phi(w) and gradient\n",
    "def subroutine(weights,Gamma):\n",
    "\n",
    "    #compute D(w)\n",
    "    wSumHalfG=(G[:,0:train_size].dot(weights)).reshape(-1,1)\n",
    "    D2=2*wSumHalfG.dot(rowSumHalfG)/train_size#the second term in Dw\n",
    "    D1=wSumHalfG.dot(np.transpose(wSumHalfG))#the first term in Dw\n",
    "    for i in range(0,train_size):\n",
    "        D1=D1-arr_m[i]*weights[i]**2\n",
    "    Dw=-2*D1+D2+np.transpose(D2)-2*D3#Dw may not be PSD\n",
    "\n",
    "    #compute S\n",
    "    M=np.linalg.solve(C,Dw)#solve matrix M for CM=Dw\n",
    "    B=np.linalg.solve(C,np.transpose(M))#solve matrix B for CB=M^\\top\n",
    "\n",
    "    evals,evecs=scipy.linalg.eigh(B, eigvals_only=False)#symmetric QR\n",
    "    Q=np.copy(evecs)\n",
    "    delta=np.copy(evals)\n",
    "    S=np.linalg.solve(np.transpose(C),Q)\n",
    "    \n",
    "    #compute bw, epsilon\n",
    "    temp2=np.multiply(np.multiply(weights,weights),P_train)\n",
    "    bw=-G[:,0:train_size]@temp2\n",
    "    epsilon=np.transpose(S).dot(bw)\n",
    "    \n",
    "    #build optimization model\n",
    "    m = Model()\n",
    "    m.Params.LogToConsole = 0#suppress Gurobipy printing\n",
    "    # Add variables\n",
    "    y=m.addMVar ( train_size*2, ub=100.0,lb=-100.0,name=\"y\" )\n",
    "    x=m.addMVar ( train_size*2, ub=100.0,lb=-100.0,name=\"x\" )    \n",
    "    # Set objective function\n",
    "    #m.Params.OptimalityTol=0.01\n",
    "    m.setObjective(epsilon@x+delta@y, GRB.MINIMIZE) \n",
    "    # Add constraints\n",
    "    m.addConstr(np.ones(train_size*2)@y<=Gamma**2)\n",
    "    m.addConstrs(x[i]@x[i]*0.5<=y[i] for i in range(train_size*2))\n",
    "    #m.params.method=0#0 is primal simplex, 1 is dual simplex, 2 is barrier\n",
    "    #m.params.NonConvex=2\n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    \n",
    "    #get key values\n",
    "    obj = m.getObjective()\n",
    "    obj_val = -obj.getValue() #return phi(w) \n",
    "    \n",
    "    x_star=np.zeros(2*train_size)\n",
    "    for i in range(0,2*train_size):\n",
    "        x_star[i]=x[i].x\n",
    "    q=S@x_star#worst case r()\n",
    "    #print('worst case revenue function r',q)\n",
    "    \n",
    "    #compute gradient\n",
    "    grad=np.zeros(train_size)\n",
    "    for i in range(0,train_size):\n",
    "        temp1=np.transpose(G[:,i]).reshape(-1,1)\n",
    "        temp2=np.transpose(wSumHalfG)-weights[i]*np.transpose(temp1)-rowSumHalfG/train_size\n",
    "        Hessian=2*temp1.dot(temp2)\n",
    "        grad[i]=q.dot(Hessian.dot(np.transpose(q)))\n",
    "        grad[i]=grad[i]+2*weights[i]*P_train[i]*np.transpose(G[:,i]).dot(q)\n",
    "    \n",
    "    return obj_val,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb2640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main loop. Frank-Wolfe algorithm \n",
    "#compute weights that minimize MSE(w) \n",
    "#use weights from nathan's method as starting point \n",
    "def FW(w,Gamma):\n",
    "\n",
    "    ini_obj,grad=subroutine(w,Gamma) \n",
    "    k=1 \n",
    "    L=Gamma*50#a guess on lipschitz constant of phi(w) \n",
    "    print('initial objective value: ',ini_obj) \n",
    "    maxIter=1000\n",
    "    MSE_arr=np.zeros(maxIter+1) \n",
    "    MSE_arr[0]=ini_obj \n",
    "    stepSize_arr=np.zeros(maxIter+1) \n",
    "    step_size=1\n",
    "    gt=0.1\n",
    "    while (gt>=0.02 and k<=maxIter):\n",
    "\n",
    "        #compute descent direction\n",
    "        obj_val,grad=subroutine(w,Gamma)\n",
    "        ind=np.argmin(grad)\n",
    "        s_t=np.zeros(train_size)\n",
    "        s_t[ind]=1\n",
    "        descent_dir=s_t-w\n",
    "\n",
    "        #compute step size\n",
    "        #step_size=2/(k+100)#default stepsize of frank-wolfe\n",
    "        gt=-grad@descent_dir\n",
    "        step_size=min(gt/(L*descent_dir@descent_dir),1)\n",
    "\n",
    "        #store key outputs\n",
    "        MSE_arr[k]=obj_val\n",
    "        stepSize_arr[k]=step_size\n",
    "\n",
    "        #update weights\n",
    "        w=w+step_size*descent_dir\n",
    "        if (k % 20==0):\n",
    "            print('iter: ',k,'obj val: ',obj_val,'gt: ',gt,'coord: ',ind)\n",
    "        k=k+1\n",
    "        \n",
    "        #if gradients are equa, then KKT conditions are satisfied\n",
    "        #max(grad)-min(grad)>=0.01\n",
    "        \n",
    "    #truncate dummy values\n",
    "    total_iter=k\n",
    "    MSE_arr=MSE_arr[0:k]\n",
    "    stepSize_arr=stepSize_arr[0:k]\n",
    "    \n",
    "    return w,MSE_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599884a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66432c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute true MSE, use our formula for MSE\n",
    "def true_MSE(w):\n",
    "    bias=w@expected_R_train-expected_val_test\n",
    "    #temp1=np.multiply(R_train,P_train-R_train)#this will be zeros since R_train is either P_train or zero\n",
    "    temp1=np.multiply(expected_R_train,P_train-expected_R_train)\n",
    "    temp2=np.multiply(w,w)\n",
    "    variance=temp1@temp2\n",
    "    #variance=expected_R_test@(P_test-expected_R_test)/(train_size**2)\n",
    "    return bias**2+variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main loop\n",
    "#test our method for oracle Gamma\n",
    "w_0=nathans_method(1)#starting point for our weights\n",
    "#Gamma_list=np.arange(1,11)*0.3#first trial\n",
    "#Gamma_list=3+np.arange(1,11)*0.2#2nd trial\n",
    "Gamma_list=np.arange(1,11)*0.3\n",
    "true_MSE_ours=np.zeros(len(Gamma_list))\n",
    "worst_MSE_ours=np.zeros(len(Gamma_list))\n",
    "est_val_ours=np.zeros(len(Gamma_list))\n",
    "w_ours_all=np.zeros((len(Gamma_list),train_size))\n",
    "w_ours=np.copy(w_0)\n",
    "for l in range(0,len(Gamma_list)):\n",
    "    Gamma=Gamma_list[l]\n",
    "    w_ours,MSE_arr=FW(w_ours,Gamma)#warm start at previous soln\n",
    "    w_ours_all[l]=w_ours#store outputs\n",
    "    true_MSE_ours[l]=true_MSE(w_ours)\n",
    "    worst_MSE_ours[l]=MSE_arr[-1]\n",
    "    est_val_ours[l]=w_ours@R_train\n",
    "    print('Gamma= ',Gamma,' complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test nathan's method for oracle lambda\n",
    "#assume Gamma=3\n",
    "#lamda_list=np.arange(1,11)#first trial\n",
    "#lamda_list=np.arange(1,11)/10#2nd trial\n",
    "#lamda_list=np.arange(1,11)*0.01#where we find oracle lambda\n",
    "lamda_list=np.arange(1,101)*0.01\n",
    "true_MSE_nathan=np.zeros(len(lamda_list))\n",
    "worst_MSE_nathan=np.zeros(len(lamda_list))\n",
    "est_val_nathan=np.zeros(len(lamda_list))\n",
    "w_nathan_all=np.zeros((len(lamda_list),train_size))\n",
    "for l in range(0,len(lamda_list)):\n",
    "    lamda=lamda_list[l]\n",
    "    w_nathan=nathans_method(lamda)\n",
    "    w_nathan_all[l]=w_nathan\n",
    "    true_MSE_nathan[l]=true_MSE(w_nathan)\n",
    "    worst_MSE_nathan[l],_=subroutine(w_nathan,3)\n",
    "    est_val_nathan[l]=w_nathan@R_train\n",
    "    if l%10==0:\n",
    "        print('lambda= ',lamda,' complete')\n",
    "\n",
    "    \n",
    "t_2 = time.time()\n",
    "print('run time: ',t_2-t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our MSE against gamma\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(Gamma_list, true_MSE_ours,label='true MSE')\n",
    "pyplot.plot(Gamma_list, worst_MSE_ours,label='worst case MSE')\n",
    "plt.scatter(Gamma_list[np.argmin(true_MSE_ours)],min(true_MSE_ours),s=20,color=\"blue\",label='min true MSE')\n",
    "pyplot.title('our method MSE')\n",
    "pyplot.xlabel('Gamma')\n",
    "pyplot.ylabel('')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot nathans MSE against gamma\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(lamda_list, true_MSE_nathan,label='true MSE')\n",
    "pyplot.plot(lamda_list, worst_MSE_nathan,label='worst case MSE')\n",
    "plt.scatter(lamda_list[np.argmin(true_MSE_nathan)],min(true_MSE_nathan),s=20,color=\"blue\",label='min true MSE')\n",
    "pyplot.title('Nathans method MSE')\n",
    "pyplot.xlabel('lambda')\n",
    "pyplot.ylabel('')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our est val against gamma\n",
    "delta=0.05\n",
    "from matplotlib import pyplot\n",
    "lb_ours=np.zeros(len(Gamma_list))\n",
    "for i in range(0,len(Gamma_list)):\n",
    "    lb_ours[i]=est_val_ours[i]-(worst_MSE_ours[i]/delta)**0.5\n",
    "pyplot.plot(Gamma_list, est_val_ours,label='estimated value')\n",
    "plt.axhline(y = expected_val_test, color = 'r', linestyle = '-',label='expected value')\n",
    "pyplot.plot(Gamma_list, lb_ours,label='lower bound')\n",
    "pyplot.title('Our method estimated value')\n",
    "pyplot.xlabel('Gamma')\n",
    "pyplot.ylabel('')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot nathans est val against lambda\n",
    "from matplotlib import pyplot\n",
    "lb_nathan=np.zeros(len(lamda_list))\n",
    "for i in range(0,len(lamda_list)):\n",
    "    lb_nathan[i]=est_val_nathan[i]-(worst_MSE_nathan[i]/delta)**0.5\n",
    "pyplot.plot(lamda_list, est_val_nathan,label='estimated value')\n",
    "plt.axhline(y = expected_val_test, color = 'r', linestyle = '-',label='expected value')\n",
    "pyplot.plot(lamda_list, lb_nathan,label='lower bound')\n",
    "pyplot.title('Nathans method estimated value')\n",
    "pyplot.xlabel('lambda')\n",
    "pyplot.ylabel('')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot our weights for different Gamma\n",
    "from matplotlib import pyplot\n",
    "for l in range(len(Gamma_list)):\n",
    "    if l%2==0:\n",
    "        plt.scatter(X_train, w_ours_all[l],alpha=0.5,label='Gamma= '+str(Gamma_list[l]))\n",
    "pyplot.title('our weights')\n",
    "pyplot.xlabel('feature X')\n",
    "pyplot.ylabel('weights')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot nathans weights for different lambda\n",
    "from matplotlib import pyplot\n",
    "for l in range(len(lamda_list)):\n",
    "    if l%20==0:\n",
    "        plt.scatter(X_train, w_nathan_all[l],alpha=0.5,label='lambda= '+str(lamda_list[l]))\n",
    "pyplot.title('Nathans weights')\n",
    "pyplot.xlabel('feature X')\n",
    "pyplot.ylabel('weights')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot nathans weights for larger lambda\n",
    "#compute weights\n",
    "lamda_list2=np.arange(1,11)\n",
    "w_nathan_all2=np.zeros((len(lamda_list2),train_size))\n",
    "for l in range(0,len(lamda_list2)):\n",
    "    w_nathan_all2[l]=nathans_method(lamda_list2[l])\n",
    "\n",
    "#plot weights\n",
    "from matplotlib import pyplot\n",
    "for l in range(len(lamda_list2)):\n",
    "    if l%2==0:\n",
    "        plt.scatter(X_train, w_nathan_all2[l],alpha=0.5,label='lambda= '+str(lamda_list2[l]))\n",
    "pyplot.title('Nathans weights')\n",
    "pyplot.xlabel('feature X')\n",
    "pyplot.ylabel('weights')\n",
    "pyplot.legend(bbox_to_anchor = (1.0, 1), loc = 'upper center')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5add36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
